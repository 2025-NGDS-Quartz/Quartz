1. 연구 개요 (500자 내외)
본 연구는 멀티에이전트 금융 의사결정 파이프라인을 AgentOps 관점에서 평가하는 벤치마크 프레임워크 QuartzOpsBench를 개발한다. 기존 벤치마크(FinBen, InvestorBench)가 모델 성능이나 수익률에 집중한다면, 본 연구는 에이전트 팀을 컨테이너 기반으로 운영했을 때의 성능·운영·안전성을 통합 평가한다. 핵심 공개물은 (1) 재현 가능한 실행 프레임워크, (2) 하루 1회 의사결정 단위의 Episode Dataset, (3) 에이전트별 근거·프롬프트·툴콜을 표준 JSON으로 기록하는 Trace Schema이다. 평가 지표는 투자 성과(Sharpe, MDD), 운영 지표(latency, 실패율, 비용), 안전/정합성 지표(정책 위반, 근거-결론 정합성)를 포함한다. 이를 통해 LLM provider만 교체하면 벤치마크 결과를 생성하는 오픈소스 툴을 제공한다.

2. 연구의 목적 및 필요성 (1500자 내외)

가. 연구의 목적
본 연구는 두 가지 목적을 갖는다. 첫째, 멀티에이전트 금융 의사결정 파이프라인을 평가하는 표준화된 벤치마크 프레임워크를 개발한다. 기존 금융 AI 평가가 모델 정확도나 수익률에 집중했다면, 본 연구는 AgentOps 관점에서 성능(Sharpe, MDD), 운영(latency, 실패율, 비용), 안전성(정책 위반, 근거-결론 정합성)을 통합 평가하는 체계를 제시한다. 둘째, 단일 LLM vs 역할 분리 멀티에이전트 vs 규칙 기반 베이스라인을 비교하여, 구조적 설계가 성능과 안정성에 미치는 영향을 실증한다. 현재 대부분의 AI 트레이딩 시스템은 하나의 모델이 시장 데이터를 해석하고 단일 결론을 도출하는 구조를 따른다. 이러한 구조는 모델의 과신, 확증 편향, 그리고 운영 환경에서의 장애 전파에 취약하다. 본 연구는 다음 가설을 검증한다.
"에이전트 팀으로 역할을 분리하고 표준화된 Trace Schema로 의사결정 과정을 기록하면, 단일 모델 대비 재현 가능성과 운영 안정성이 향상되며, 이를 통해 최적의 성능을 가지는 시스템을 찾을 수 있다."
 
나. 연구의 필요성
기존 금융 AI 벤치마크는 태스크 다양성(FinBen: 42 datasets/24 tasks)이나 투자 성과 지표(InvestorBench: 수익률/리스크)에 집중해왔다. 최근에는 주문 레벨(슬리피지/지연/호가 미시구조)까지 포함한 시뮬레이터(StockSim)도 등장했다. 그러나 에이전트 파이프라인을 쿠버네티스/마이크로서비스로 운영했을 때의 지연시간, 실패율, 비용, rate-limit 내성 같은 "운영 지표"를 평가하는 벤치마크는 부재하다. 또한 에이전트별 근거·프롬프트·툴콜을 표준화된 형식으로 기록하여 재현 가능성을 확보하는 체계도 없다. 실제 금융 시스템에서는 모델 정확도만큼이나 운영 안정성이 중요하다. 에이전트 장애 시 장애 전파를 막고, 의사결정 과정을 감사(audit)할 수 있어야 한다. 이러한 AgentOps 관점의 평가 체계와 리플레이 가능한 트레이스 데이터셋을 구축할 필요가 있다.
 
다. 연구의 창의성
본 연구의 창의성은 세 가지로 요약된다.
첫째, 금융 LLM 평가를 AgentOps 관점으로 확장한다. 기존 벤치마크가 모델 성능이나 수익률에 집중했다면, 본 연구는 운영 지표(latency, 실패율, 비용, rate-limit 내성)와 안전/정합성 지표(정책 위반, 근거-결론 정합성)를 평가 체계에 포함한다.
둘째, 리플레이 가능한 Trace Schema를 제안한다. 에이전트별 근거 링크, 지표 값, 프롬프트 버전, 툴콜 로그를 표준 JSON으로 기록하여, 동일 입력에서 동일 결과를 재현할 수 있는 체계를 구축한다. 이를 통해 LLM provider만 교체하면 벤치마크 결과를 생성할 수 있다.
셋째, 구조적 설계의 영향을 실증한다. 단일 LLM vs 역할 분리 멀티에이전트 vs 규칙 기반 베이스라인을 동일 조건에서 비교하여, 에이전트 팀 구조가 성능·운영·안전성에 미치는 영향을 정량적으로 분석한다.

3. 연구 내용 및 방법 (2000자 내외)
가. 연구 내용
본 연구는 멀티에이전트 금융 의사결정 파이프라인을 평가하는 벤치마크 프레임워크 QuartzOpsBench를 개발한다.
(1) quartzopsbench 실행 프레임워크 개발 AgentBench의 "환경+평가 루프" 구조를 차용하여 도커 기반 재현 가능한 실행 환경을 구축한다. 각 에이전트(거시경제 분석, 뉴스 감성, 기술분석, 포트폴리오, 주문 실행)를 독립 컨테이너로 패키징하고, docker-compose로 전체 파이프라인을 단일 명령어로 실행할 수 있도록 한다. 환경변수로 LLM provider(OpenAI, Google, Anthropic)와 모델 버전을 지정하면 동일한 Episode Dataset에 대해 벤치마크 결과를 자동 생성한다. seed 고정, 프롬프트 버전 관리, API 응답 캐싱을 통해 재현성을 확보한다.
(2) Episode Dataset 구축 "하루 1회 의사결정" 단위의 에피소드 데이터셋을 구축한다. 각 에피소드는 다음으로 구성된다: - 입력 스냅샷: ECOS/FRED 거시지표, 당일 뉴스 크롤링 결과(네이버/한경/매경), KOSPI 200 종목 OHLCV, RSI/MACD/볼린저밴드 등 기술지표 - 출력: 선정 종목 리스트, 매수/매도 주문 계획, 포지션 한도/손절 규칙, 각 결정의 근거 텍스트 - 결과: 백테스트 수익률/MDD + API 호출 실패/지연/토큰 비용 로그 2024년 1월~12월 약 250 거래일 분량의 에피소드를 수집하여 경량 데이터셋으로 공개한다.
(3) Trace Schema 표준화 에이전트 간 정보 흐름과 의사결정 근거를 표준 JSON으로 기록하는 스키마를 정의한다. 각 트레이스는 에이전트 ID, 타임스탬프, 입력 데이터 해시, 프롬프트 버전, LLM 응답 원문, 파싱된 결정, 툴콜 로그(API 호출 URL/응답시간/상태코드)를 포함한다. 이를 통해 "왜 이 종목을 선정했는가"를 사후 추적하고, 동일 입력에서 결과를 재현할 수 있다.

나. 연구 방법
(1) 평가 지표 체계 세 가지 축으로 평가한다:
- 투자 성과: 누적수익률, Sharpe ratio, MDD, 거래회전율. InvestorBench 기준을 따른다.
- 운영 지표: 의사결정 latency(에피소드당 총 소요시간), API 실패율/재시도율, 토큰 비용(원화 환산), rate-limit 도달 빈도.
- 안전/정합성: 포지션 한도 초과 빈도, 손절 규칙 위반 빈도, 근거-결론 정합성(근거 텍스트 없이 결정을 내린 비율).
(2) 비교 실험 설계 세 가지 조건을 동일 Episode Dataset으로 비교한다:
- (A) 단일 LLM: 모든 데이터를 하나의 프롬프트에 넣고 GPT-4o가 직접 종목 선정/주문 계획을 출력
- (B) 규칙 기반: RSI 25 이하 매수, 65 이상 매도 등 고정 규칙 알고리즘
- (C) 멀티에이전트(Quartz): 거시경제→뉴스→기술분석→포트폴리오→주문 순서로 에이전트가 협력 각 조건에서 투자 성과, 운영 지표, 안전/정합성 지표를 측정하여 구조적 설계가 성능과 안정성에 미치는 영향을 정량적으로 분석한다.
(3) LLM provider 교체 실험 동일한 멀티에이전트 구조에서 LLM provider를 GPT-4o, Gemini-1.5-Pro, Claude-3.5-Sonnet으로 교체하고 성능 차이를 비교한다. 이를 통해 "프레임워크는 동일하되 모델만 바꾸면 벤치마크 결과가 나온다"는 도구의 범용성을 검증한다.

다. 기대효과 및 활용 방안
(1) 학술적 기여 금융 LLM 평가를 AgentOps 관점으로 확장한 벤치마크와 Trace Schema 표준을 제시한다. 단일 LLM vs 멀티에이전트 vs 규칙 기반 비교를 통해 "구조적 설계가 성능/안정성에 주는 영향"을 실증한다.
(2) 산업 적용 가능성 LLM provider만 교체하면 벤치마크 결과를 생성할 수 있어, 금융사가 자사 에이전트 파이프라인을 프로덕션 배포 전 검증하는 데 활용 가능하다.
(3) 오픈소스 생태계 기여 실행 프레임워크, Episode Dataset, Trace Schema를 GitHub에 공개하여 후속 연구자들이 벤치마크를 확장하고 재현할 수 있는 기반을 제공한다.
※ 학술·정책·콘텐츠·교육 적용 가능성 등

4. 최종 결과물 (500자 내외)
(1) 학술 논문 "QuartzOpsBench: Operational, Reproducible, and Secure Evaluation of Multi-Agent Financial Decision Pipelines"를 주제로 국내외 학술대회(KSC, EMNLP, ACL Findings 등)에 투고를 목표로 한다. 금융 LLM 평가를 AgentOps 관점으로 확장한 기여와 Trace Schema 표준화를 핵심 contribution으로 제시한다.
(2) 오픈소스 벤치마크 툴 quartzopsbench 실행 프레임워크를 GitHub에 공개한다. 컨테이너 기반(도커/k3s)으로 재현 가능한 실행 환경, LLM provider 교체만으로 벤치마크 결과를 생성하는 인터페이스, 평가 지표(투자 성과/운영/안전성) 자동 산출 기능을 포함한다.
(3) Episode Dataset + Trace Schema "하루 1회 의사결정" 단위의 Episode Dataset(입력 스냅샷/출력/성과 로그)과 에이전트별 근거·지표·프롬프트·툴콜을 기록하는 Trace Schema 규격을 공개한다. 이를 통해 후속 연구자들이 동일 조건에서 멀티에이전트 금융 의사결정을 재현하고 확장할 수 있는 기반을 제공한다.

5. 지도교수 자문계획 (500자 내외)

본 연구는 금융 멀티에이전트 의사결정 파이프라인을 AgentOps 관점에서 표준화·재현 가능하게 평가하는 것이 핵심이므로, 교수님께는(1) 연구 기여의 명확화(FinBen/InvestorBench 대비 novelty, 논문 스토리라인과 가설 검증 구조)(2) 평가지표 설계의 타당성(운영 지표 정의·측정 방법, 안전/정합성 지표의 정량화 기준과 채점 루브릭)(3) Episode Dataset/Trace Schema의 학술적 완결성(스키마 필수 필드, 재현성 보장 장치(seed·캐싱·프롬프트 버전관리), 데이터 공개 범위와 윤리/저작권 이슈)(4) 실험 설계의 공정성(단일 LLM/규칙 기반/멀티에이전트 비교 조건 통제, provider 교체 실험의 통계적 해석, 실패·지연·비용 로그 수집 방법)(5) 오픈소스 배포 전략(리포 구조, 사용성, 벤치마크 확장 포인트, 리뷰어 관점의 재현 패키징) 중심으로 자문을 요청드리고자 한다. 이를 통해 논문 투고 가능 수준의 기여 정리와, 실제로 “한 번의 실행으로 결과가 재현되는” 벤치마크 도구로 완성하고자 한다.


6. 팀원별 개인 목표
강연욱: 평소 금융 및 AI 분야에 관심이 많았고, 변수가 많고 단순한 시스템으로는 분석이 불가능한 금융 도메인의 문제를 AI를 통해 해결해보고 싶다. AI 스타트업에서 재직하며 AI 관련 연구를 해보고 싶단 생각이 항상 마음 속에 있었는데, 이번 드림학기제를 통해 AI 에이전트와 에이전트 간 통신 프로토콜, 분산 환경에서 다수의 에이전트 운영 경험을 얻고, 이를 기반으로 논문과 오픈소스 벤치마크 배포까지 진행하는 학술적 기여도 경험하고 싶다.
김장수: 본 프로젝트를 통해 LLM 기반 멀티에이전트 시스템의 실제 설계·운영 경험을 쌓고자 한다. 특히 에이전트 간 역할 분담과 통신 구조가 의사결정 품질에 미치는 영향을 직접 검증하며, 금융 도메인에서 신뢰성 있는 자동화 시스템을 구현해보는 경험을 하고자 한다.
오성현: 평소에 주식이나 ETF에 관심이 많았던만큼 노베이스에서 AI기반의 온전한 서비스를 구현해내는 과정을 직접 겪어내며, 그 안에서 스스로의 한계를 시험해보고 싶다.오류와 문제들을 마주하더라도 회피하지 않고 새로운 지식과 정보, 기술들을 공부하고 노력해가며 그 문제들을 해결해나가는 끈기를 기르고, 혼자였다면 불가능할만한 태스크들도 협업하며 해결하는것을 배우고싶다. 또한 실제 시스템을 설계 및 운영해보면서 실무와 유사한 경험을 쌓을 수 있는 기회라고 생각한다.



7. 팀원별 담당업무 (학과, 성명, 신청학점, 담당업무 작성)
강연욱(공과대학 컴퓨터공학부, 12학점): 전체 시스템 아키텍처 설계 및 에이전트 간 통신 프로토콜 구현, 도커 기반 컨테이너 환경 구축, LLM provider 교체 인터페이스 개발, 논문 작성 및 오픈소스 리포지토리 관리를 담당한다.
김장수(공과대학 컴퓨터공학부, 12학점): 멀티에이전트 시스템 구현 및 Trace Schema 표준화, 에이전트별 근거와 툴콜 로그를 기록하는 트레이싱 시스템 개발, 투자 성과 및 운영 지표 측정 모듈 구현을 담당한다.
오성현(공과대학 컴퓨터공학부, 12학점): 금융 데이터 파이프라인 및 Episode Dataset 구축, ECOS, FRED 거시지표와 국내 뉴스 크롤링, KOSPI 200 종목 시계열 데이터 수집, 백테스트 시뮬레이터 개발을 담당한다.



| 구분 | 목표 | 핵심활동 | 산출물/결과물 | 투입시간 |
|------|------|----------|---------------|----------|
| 1주차 | 프로젝트 셋업 및 환경 구성 | - 개발 환경 구축 (Docker, k3s)<br>- 기존 Quartz 코드베이스 분석<br>- AgentBench 구조 리서치 | 개발 환경 구성 완료<br>기술 스택 문서 | 20h |
| 2주차 | 실행 프레임워크 설계 | - quartzopsbench 아키텍처 설계<br>- 에이전트별 컨테이너 구조 정의<br>- docker-compose 템플릿 작성 | 아키텍처 설계 문서<br>docker-compose.yml 초안 | 20h |
| 3주차 | 실행 프레임워크 개발 (1) | - 에이전트 컨테이너 패키징<br>- LLM provider 환경변수 인터페이스 구현<br>- seed 고정 및 재현성 로직 구현 | 에이전트별 Dockerfile<br>LLM provider 추상화 모듈 | 25h |
| 4주차 | 실행 프레임워크 개발 (2) | - 평가 루프(evaluation loop) 구현<br>- API 응답 캐싱 시스템 구축<br>- 프롬프트 버전 관리 시스템 | 실행 프레임워크 v0.1<br>캐싱 모듈 | 25h |
| 5주차 | Episode Dataset 설계 | - 에피소드 스키마 정의<br>- 데이터 수집 파이프라인 설계<br>- 입력 스냅샷 구조 확정 | Episode 스키마 문서<br>데이터 수집 설계서 | 20h |
| 6주차 | Episode Dataset 구축 (1) | - ECOS/FRED 거시지표 수집<br>- 뉴스 크롤링 데이터 정제<br>- KOSPI 200 OHLCV 수집 | 거시지표 데이터셋<br>뉴스 데이터셋 (2024.1~6월) | 25h |
| 7주차 | Episode Dataset 구축 (2) | - 기술지표(RSI/MACD/볼린저) 산출<br>- 2024.7~12월 데이터 수집<br>- 데이터 정합성 검증 | Episode Dataset v1.0<br>(약 250 거래일) | 25h |
| 8주차 | Trace Schema 표준화 | - Trace Schema JSON 규격 정의<br>- 에이전트별 로깅 인터페이스 구현<br>- 툴콜 로그 포맷 설계 | Trace Schema 규격 문서<br>로깅 모듈 | 20h |
| 9주차 | 평가 지표 체계 구현 | - 투자 성과 지표 산출 모듈<br>- 운영지표(latency/실패율/비용) 측정<br>- 안전/정합성 지표 구현 | 평가 지표 산출 모듈<br>지표 대시보드 | 25h |
| 10주차 | 베이스라인 구현 | - (A) 단일 LLM 베이스라인 구현<br>- (B) 규칙 기반 알고리즘 구현<br>- 베이스라인 테스트 | 단일 LLM 파이프라인<br>규칙 기반 파이프라인 | 25h |
| 11주차 | 비교 실험 (1) | - 단일 LLM vs 규칙 기반 vs Quartz 실험<br>- 투자 성과 지표 측정<br>- 초기 결과 분석 | 비교 실험 결과 (성과 지표)<br>중간 분석 보고서 | 25h |
| 12주차 | 비교 실험 (2) | - 운영 지표/안전성 지표 측정<br>- 실험 결과 정리 및 시각화<br>- 통계적 유의성 검증 | 전체 비교 실험 결과<br>결과 시각화 자료 | 25h |
| 13주차 | LLM provider 교체 실험 | - GPT-4o / Gemini-1.5-Pro / Claude-3.5 비교<br>- provider별 성능/비용 분석<br>- 프레임워크 범용성 검증 | LLM provider 비교 결과<br>비용 분석 보고서 | 25h |
| 14주차 | 논문 초고 작성 | - 논문 구조 및 초록 작성<br>- Introduction / Related Work 작성<br>- Methodology 작성 | 논문 초고 (50%) | 25h |
| 15주차 | 논문 완성 및 오픈소스 정리 | - Experiments / Results 작성<br>- Conclusion 작성<br>- GitHub 저장소 정리 및 README 작성 | 논문 초고 (100%)<br>GitHub 저장소 공개 준비 | 25h |
| 16주차 | 최종 검토 및 제출 | - 논문 피드백 반영 및 수정<br>- 오픈소스 문서화 완료<br>- 학회 투고 준비 | 최종 논문<br>quartzopsbench 오픈소스 공개<br>Episode Dataset + Trace Schema 공개 | 20h |