# QuartzOpsBench 주차별 진행일정 및 상세내용

## 1주차: 프로젝트 셋업 및 환경 구성

### 주요목표 및 활동
Docker 및 k3s 기반 개발 환경을 구축하고, 기존 Quartz 코드베이스를 분석한다. AgentBench의 "환경+평가 루프" 구조를 리서치하여 quartzopsbench 설계의 기반을 마련한다.

### 상세내용
본 주차에서는 프로젝트의 기술적 토대를 구축한다. Docker 컨테이너 환경과 k3s 클러스터를 로컬에 구성하여 멀티에이전트 파이프라인 실행 환경을 준비한다. 기존 Quartz 코드베이스의 에이전트 구조(거시경제 분석, 뉴스 감성, 기술분석, 포트폴리오, 주문 실행)를 분석하고, 각 에이전트의 입출력 인터페이스를 파악한다. AgentBench 논문과 구현체를 리서치하여 재현 가능한 벤치마크 프레임워크의 핵심 설계 원칙을 도출한다. 팀 전체가 동일한 개발 환경에서 작업할 수 있도록 기술 스택 문서를 작성하고, Git 브랜치 전략 및 코드 리뷰 프로세스를 확정한다.

### 팀원별 목표 및 활동 (투입시간: 인당 20h)
- **강연욱**: Docker 및 k3s 클러스터 환경 구축, 컨테이너 오케스트레이션 설정, 개발 환경 표준화 문서 작성 (20h)
- **김장수**: 기존 Quartz 에이전트 코드베이스 분석, 에이전트 간 통신 흐름 파악, 현행 로깅 구조 분석 (20h)
- **오성현**: AgentBench 구조 리서치, 데이터 파이프라인 현황 분석, 금융 데이터 소스(ECOS/FRED/뉴스) 접근 방법 조사 (20h)

---

## 2주차: 실행 프레임워크 설계

### 주요목표 및 활동
quartzopsbench 아키텍처를 설계하고, 에이전트별 컨테이너 구조를 정의한다. docker-compose 템플릿을 작성하여 단일 명령어로 전체 파이프라인을 실행할 수 있는 구조를 설계한다.

### 상세내용
AgentBench의 "환경+평가 루프" 구조를 차용하여 quartzopsbench의 전체 아키텍처를 설계한다. 각 에이전트(거시경제 분석, 뉴스 감성, 기술분석, 포트폴리오, 주문 실행)를 독립 컨테이너로 패키징하는 구조를 정의하고, 에이전트 간 데이터 흐름과 의존성을 명시한다. 환경변수로 LLM provider(OpenAI, Google, Anthropic)와 모델 버전을 지정하는 인터페이스를 설계한다. docker-compose.yml 템플릿을 작성하여 개발/테스트/벤치마크 실행 환경을 분리하고, 네트워크 구성 및 볼륨 마운트 전략을 확정한다. 아키텍처 설계 문서를 작성하여 팀원 간 설계 의도를 공유한다.

### 팀원별 목표 및 활동 (투입시간: 인당 20h)
- **강연욱**: 전체 시스템 아키텍처 설계, docker-compose 템플릿 작성, 컨테이너 간 네트워크 구성 설계, 아키텍처 설계 문서 작성 (20h)
- **김장수**: 에이전트 간 통신 프로토콜 설계, Trace Schema 초안 설계, 에이전트별 입출력 인터페이스 정의 (20h)
- **오성현**: 데이터 파이프라인 아키텍처 설계, 외부 API 연동 구조 설계, 데이터 캐싱 전략 수립 (20h)

---

## 3주차: 실행 프레임워크 개발 (1)

### 주요목표 및 활동
에이전트별 Dockerfile을 작성하고 컨테이너를 패키징한다. LLM provider 환경변수 인터페이스를 구현하고, seed 고정 및 재현성 로직을 구현한다.

### 상세내용
설계된 아키텍처를 바탕으로 실행 프레임워크 개발에 착수한다. 각 에이전트(거시경제 분석, 뉴스 감성, 기술분석, 포트폴리오, 주문 실행)를 독립적인 Docker 이미지로 빌드할 수 있도록 Dockerfile을 작성한다. LLM provider 추상화 모듈을 구현하여 환경변수만으로 GPT-4o, Gemini-1.5-Pro, Claude-3.5-Sonnet 간 전환이 가능하도록 한다. 재현 가능한 벤치마크를 위해 random seed 고정 로직을 구현하고, 동일 입력에서 동일 결과를 보장하는 결정론적 실행 환경을 구축한다. 에이전트별 헬스체크 엔드포인트를 구현하여 컨테이너 상태 모니터링 기반을 마련한다.

### 팀원별 목표 및 활동 (투입시간: 인당 25h)
- **강연욱**: 에이전트별 Dockerfile 작성, LLM provider 추상화 모듈 구현, seed 고정 로직 구현, 컨테이너 빌드 파이프라인 구축 (25h)
- **김장수**: 에이전트 간 통신 프로토콜 구현, 메시지 큐 또는 REST API 기반 통신 모듈 개발, 에이전트 헬스체크 구현 (25h)
- **오성현**: 데이터 수집 에이전트 컨테이너화, 외부 API 클라이언트 모듈 구현, 데이터 전처리 파이프라인 컨테이너화 (25h)

---

## 4주차: 실행 프레임워크 개발 (2)

### 주요목표 및 활동
평가 루프(evaluation loop)를 구현하고, API 응답 캐싱 시스템을 구축한다. 프롬프트 버전 관리 시스템을 개발하여 실행 프레임워크 v0.1을 완성한다.

### 상세내용
벤치마크 실행의 핵심인 평가 루프를 구현한다. 에피소드 단위로 입력 데이터를 로드하고, 에이전트 파이프라인을 순차 실행하며, 결과를 수집하는 일련의 과정을 자동화한다. LLM API 호출 비용 절감과 재현성 확보를 위해 API 응답 캐싱 시스템을 구축한다. 동일한 프롬프트와 입력에 대해 캐시된 응답을 반환하여 반복 실험의 효율성을 높인다. 프롬프트 버전 관리 시스템을 구현하여 각 실험에서 사용된 프롬프트 버전을 추적할 수 있도록 한다. 이를 통해 실행 프레임워크 v0.1을 완성하고, 단일 명령어로 벤치마크를 실행할 수 있는 환경을 구축한다.

### 팀원별 목표 및 활동 (투입시간: 인당 25h)
- **강연욱**: 평가 루프(evaluation loop) 구현, 에피소드 실행 오케스트레이션 개발, 실행 프레임워크 v0.1 통합 및 테스트 (25h)
- **김장수**: API 응답 캐싱 시스템 구축, 캐시 키 생성 로직 구현, 프롬프트 버전 관리 시스템 개발 (25h)
- **오성현**: 데이터 로더 모듈 구현, 에피소드별 입력 스냅샷 생성 로직 개발, 캐싱 시스템과 데이터 파이프라인 연동 (25h)

---

## 5주차: Episode Dataset 설계

### 주요목표 및 활동
"하루 1회 의사결정" 단위의 에피소드 스키마를 정의하고, 데이터 수집 파이프라인을 설계한다. 입력 스냅샷의 구조를 확정하여 Episode Dataset 구축의 기반을 마련한다.

### 상세내용
Episode Dataset의 핵심 스키마를 정의한다. 각 에피소드는 입력 스냅샷(ECOS/FRED 거시지표, 당일 뉴스 크롤링 결과, KOSPI 200 종목 OHLCV, 기술지표), 출력(선정 종목 리스트, 매수/매도 주문 계획, 포지션 한도/손절 규칙, 결정 근거 텍스트), 결과(백테스트 수익률/MDD, API 호출 로그)로 구성된다. 데이터 수집 파이프라인의 상세 설계를 수행하여 ECOS API, FRED API, 뉴스 크롤러, 증권사 API 연동 방법을 확정한다. 데이터 정합성 검증 규칙과 결측치 처리 정책을 수립한다. Episode 스키마 문서와 데이터 수집 설계서를 작성하여 구현 가이드라인을 제공한다.

### 팀원별 목표 및 활동 (투입시간: 인당 20h)
- **강연욱**: Episode 스키마 JSON 규격 정의, 에피소드 저장/로드 인터페이스 설계, 스키마 문서 작성 (20h)
- **김장수**: 출력 데이터 스키마 설계, 결정 근거 텍스트 구조 정의, 백테스트 결과 스키마 설계 (20h)
- **오성현**: 입력 스냅샷 구조 설계, 데이터 수집 파이프라인 상세 설계, ECOS/FRED/뉴스 API 연동 방법 확정, 데이터 수집 설계서 작성 (20h)

---

## 6주차: Episode Dataset 구축 (1)

### 주요목표 및 활동
ECOS/FRED 거시지표를 수집하고, 뉴스 크롤링 데이터를 정제한다. 2024년 1월~6월 분량의 데이터셋을 구축하여 Episode Dataset의 전반부를 완성한다.

### 상세내용
설계된 파이프라인을 바탕으로 실제 데이터 수집에 착수한다. 한국은행 ECOS API를 통해 금리, 환율, 물가지수 등 거시경제지표를 수집하고, FRED API를 통해 미국 연준 금리, 고용지표 등 글로벌 거시지표를 수집한다. 네이버 금융, 한국경제, 매일경제에서 2024년 1월~6월 기간의 뉴스 데이터를 크롤링하고, 중복 제거 및 텍스트 정제를 수행한다. KOSPI 200 구성 종목의 일별 OHLCV 데이터를 수집하여 시계열 데이터베이스를 구축한다. 수집된 데이터의 품질을 검증하고, 결측치 및 이상치를 처리하여 깨끗한 데이터셋을 확보한다.

### 팀원별 목표 및 활동 (투입시간: 인당 25h)
- **강연욱**: 데이터 수집 자동화 스크립트 개발, 데이터 저장소(S3/로컬) 구성, 데이터 파이프라인 모니터링 구축 (25h)
- **김장수**: 뉴스 데이터 정제 및 전처리 모듈 개발, 텍스트 정규화 및 중복 제거 로직 구현 (25h)
- **오성현**: ECOS/FRED API 연동 및 거시지표 수집, 뉴스 크롤러 실행 및 데이터 수집, KOSPI 200 OHLCV 데이터 수집 (25h)

---

## 7주차: Episode Dataset 구축 (2)

### 주요목표 및 활동
RSI, MACD, 볼린저밴드 등 기술지표를 산출하고, 2024년 7월~12월 데이터를 수집한다. 데이터 정합성을 검증하여 약 250 거래일 분량의 Episode Dataset v1.0을 완성한다.

### 상세내용
수집된 OHLCV 데이터를 바탕으로 기술적 분석 지표를 산출한다. RSI(상대강도지수), MACD(이동평균수렴확산), 볼린저밴드, 이동평균선(5/20/60/120일) 등 핵심 기술지표를 계산하여 각 에피소드의 입력 스냅샷에 포함한다. 2024년 7월~12월 기간의 거시지표, 뉴스, OHLCV 데이터를 추가 수집하여 연간 데이터셋을 완성한다. 전체 데이터셋에 대한 정합성 검증을 수행하여 날짜 누락, 데이터 불일치, 기술지표 계산 오류 등을 점검한다. 최종적으로 약 250 거래일 분량의 Episode Dataset v1.0을 완성하고, 데이터셋 품질 보고서를 작성한다.

### 팀원별 목표 및 활동 (투입시간: 인당 25h)
- **강연욱**: Episode Dataset 통합 및 버전 관리, 데이터셋 배포 패키징, 데이터셋 문서화 (25h)
- **김장수**: 기술지표(RSI/MACD/볼린저밴드) 산출 모듈 구현, 지표 계산 검증 및 테스트 (25h)
- **오성현**: 2024년 7월~12월 데이터 수집, 데이터 정합성 검증, 결측치/이상치 처리, Episode Dataset v1.0 완성 (25h)

---

## 8주차: Trace Schema 표준화

### 주요목표 및 활동
에이전트별 근거, 프롬프트, 툴콜을 기록하는 Trace Schema JSON 규격을 정의한다. 로깅 인터페이스를 구현하여 의사결정 과정의 추적 가능성을 확보한다.

### 상세내용
에이전트 간 정보 흐름과 의사결정 근거를 표준 JSON으로 기록하는 Trace Schema를 정의한다. 각 트레이스는 에이전트 ID, 타임스탬프, 입력 데이터 해시, 프롬프트 버전, LLM 응답 원문, 파싱된 결정, 툴콜 로그(API 호출 URL/응답시간/상태코드)를 포함한다. 에이전트별로 통일된 로깅 인터페이스를 구현하여, 모든 에이전트가 동일한 형식으로 트레이스를 기록하도록 한다. 툴콜 로그 포맷을 설계하여 외부 API 호출의 URL, 요청/응답 시간, HTTP 상태코드, 토큰 사용량을 기록한다. 이를 통해 "왜 이 종목을 선정했는가"를 사후 추적하고, 동일 입력에서 결과를 재현할 수 있는 체계를 구축한다.

### 팀원별 목표 및 활동 (투입시간: 인당 20h)
- **강연욱**: Trace Schema JSON 규격 검토 및 승인, 트레이스 저장소 구성, Trace Schema 규격 문서 작성 (20h)
- **김장수**: Trace Schema JSON 규격 정의, 에이전트별 로깅 인터페이스 구현, 툴콜 로그 포맷 설계, 트레이스 수집 모듈 개발 (20h)
- **오성현**: 데이터 파이프라인 트레이스 로깅 구현, 외부 API 호출 로그 기록 모듈 개발, 입력 데이터 해시 생성 로직 구현 (20h)

---

## 9주차: 평가 지표 체계 구현

### 주요목표 및 활동
투자 성과 지표(Sharpe, MDD), 운영 지표(latency, 실패율, 비용), 안전/정합성 지표를 산출하는 모듈을 구현한다. 평가 결과를 시각화하는 대시보드를 개발한다.

### 상세내용
세 가지 축의 평가 지표 산출 모듈을 구현한다. 투자 성과 지표로는 누적수익률, Sharpe ratio, MDD(최대낙폭), 거래회전율을 InvestorBench 기준에 따라 산출한다. 운영 지표로는 의사결정 latency(에피소드당 총 소요시간), API 실패율/재시도율, 토큰 비용(원화 환산), rate-limit 도달 빈도를 측정한다. 안전/정합성 지표로는 포지션 한도 초과 빈도, 손절 규칙 위반 빈도, 근거-결론 정합성(근거 텍스트 없이 결정을 내린 비율)을 산출한다. 모든 지표를 한눈에 파악할 수 있는 대시보드를 개발하여 벤치마크 결과의 가시성을 높인다.

### 팀원별 목표 및 활동 (투입시간: 인당 25h)
- **강연욱**: 평가 지표 대시보드 개발, 지표 시각화 컴포넌트 구현, 벤치마크 결과 리포트 생성기 개발 (25h)
- **김장수**: 투자 성과 지표(Sharpe/MDD/수익률) 산출 모듈 구현, 운영 지표(latency/실패율/비용) 측정 모듈 구현, 안전/정합성 지표 산출 로직 개발 (25h)
- **오성현**: 백테스트 시뮬레이터 개발, 거래 시뮬레이션 엔진 구현, 수익률/MDD 계산 검증 (25h)

---

## 10주차: 베이스라인 구현

### 주요목표 및 활동
비교 실험을 위한 (A) 단일 LLM 베이스라인과 (B) 규칙 기반 알고리즘을 구현한다. 베이스라인 테스트를 수행하여 비교 실험의 기반을 마련한다.

### 상세내용
멀티에이전트 시스템(Quartz)과 비교할 두 가지 베이스라인을 구현한다. (A) 단일 LLM 베이스라인은 모든 데이터(거시지표, 뉴스, 기술지표)를 하나의 프롬프트에 넣고 GPT-4o가 직접 종목 선정과 주문 계획을 출력하는 구조이다. (B) 규칙 기반 베이스라인은 RSI 25 이하 매수, 65 이상 매도 등 고정된 기술적 분석 규칙을 따르는 알고리즘이다. 각 베이스라인을 Episode Dataset의 일부에 대해 테스트하여 정상 동작을 확인하고, 투자 성과/운영/안전성 지표 산출이 올바르게 이루어지는지 검증한다.

### 팀원별 목표 및 활동 (투입시간: 인당 25h)
- **강연욱**: 단일 LLM 베이스라인 프롬프트 설계 및 구현, LLM 응답 파싱 로직 개발, 베이스라인 실행 파이프라인 구축 (25h)
- **김장수**: 규칙 기반 알고리즘 구현, RSI/MACD 기반 매매 규칙 코딩, 베이스라인 트레이스 로깅 연동 (25h)
- **오성현**: 베이스라인 테스트 데이터 준비, 베이스라인별 백테스트 실행, 초기 성능 검증 및 디버깅 (25h)

---

## 11주차: 비교 실험 (1)

### 주요목표 및 활동
단일 LLM vs 규칙 기반 vs Quartz(멀티에이전트) 비교 실험을 수행한다. 투자 성과 지표를 중심으로 초기 결과를 분석하고 중간 분석 보고서를 작성한다.

### 상세내용
동일한 Episode Dataset에 대해 세 가지 조건의 비교 실험을 수행한다. (A) 단일 LLM, (B) 규칙 기반, (C) Quartz 멀티에이전트 각각을 전체 250 에피소드에 대해 실행하고, 투자 성과 지표(누적수익률, Sharpe ratio, MDD, 거래회전율)를 측정한다. 각 조건의 종목 선정 패턴과 매매 결정을 분석하여 구조적 차이가 성과에 미치는 영향을 파악한다. 초기 결과를 바탕으로 중간 분석 보고서를 작성하여 연구 가설 "에이전트 팀으로 역할을 분리하면 단일 모델 대비 성능이 향상된다"의 검증 방향을 설정한다.

### 팀원별 목표 및 활동 (투입시간: 인당 25h)
- **강연욱**: 비교 실험 오케스트레이션, 실험 실행 자동화 스크립트 개발, 실험 결과 수집 및 저장 (25h)
- **김장수**: 투자 성과 지표 측정 및 분석, 조건별 성과 비교 분석, 중간 분석 보고서 작성 (25h)
- **오성현**: 백테스트 실행 및 결과 검증, 종목 선정 패턴 분석, 실험 데이터 품질 관리 (25h)

---

## 12주차: 비교 실험 (2)

### 주요목표 및 활동
운영 지표와 안전/정합성 지표를 측정하고, 실험 결과를 시각화한다. 통계적 유의성을 검증하여 비교 실험의 신뢰성을 확보한다.

### 상세내용
11주차에 이어 운영 지표와 안전/정합성 지표를 측정한다. 각 조건의 의사결정 latency, API 실패율, 토큰 비용, rate-limit 도달 빈도를 비교하여 운영 효율성을 분석한다. 포지션 한도 초과, 손절 규칙 위반, 근거-결론 정합성 등 안전/정합성 지표를 측정하여 시스템의 신뢰성을 평가한다. 모든 실험 결과를 차트와 표로 시각화하고, t-test 또는 부트스트래핑을 통해 조건 간 차이의 통계적 유의성을 검증한다. 전체 비교 실험 결과를 정리하여 논문 Experiments 섹션의 기초 자료를 확보한다.

### 팀원별 목표 및 활동 (투입시간: 인당 25h)
- **강연욱**: 실험 결과 시각화 개발, 차트/표 생성 자동화, 결과 대시보드 업데이트 (25h)
- **김장수**: 운영 지표/안전성 지표 측정 및 분석, 통계적 유의성 검증(t-test/부트스트래핑), 전체 비교 실험 결과 정리 (25h)
- **오성현**: 안전/정합성 지표 데이터 수집, 포지션 한도/손절 규칙 위반 분석, 근거-결론 정합성 검증 (25h)

---

## 13주차: LLM provider 교체 실험

### 주요목표 및 활동
동일한 멀티에이전트 구조에서 GPT-4o, Gemini-1.5-Pro, Claude-3.5-Sonnet을 교체하여 비교한다. provider별 성능/비용 분석을 통해 프레임워크의 범용성을 검증한다.

### 상세내용
quartzopsbench의 핵심 기능인 "LLM provider 교체만으로 벤치마크 결과 생성"을 검증한다. 멀티에이전트(Quartz) 구조를 유지한 채 LLM provider를 GPT-4o, Gemini-1.5-Pro, Claude-3.5-Sonnet으로 교체하고, 동일 Episode Dataset에 대해 실험을 수행한다. 각 provider별 투자 성과, 운영 지표, 안전/정합성 지표를 비교하여 모델 특성이 금융 의사결정에 미치는 영향을 분석한다. 특히 토큰 비용과 API 응답 시간을 비교하여 비용 효율성 분석 보고서를 작성한다. 이를 통해 프레임워크가 특정 LLM에 종속되지 않고 범용적으로 활용될 수 있음을 실증한다.

### 팀원별 목표 및 활동 (투입시간: 인당 25h)
- **강연욱**: LLM provider 교체 인터페이스 최종 검증, provider별 실험 실행, API 연동 이슈 해결 (25h)
- **김장수**: provider별 성능 지표 측정 및 비교 분석, 비용 효율성 분석, 프레임워크 범용성 검증 보고서 작성 (25h)
- **오성현**: provider별 실험 데이터 관리, 응답 품질 비교 분석, 비용 분석 보고서 작성 지원 (25h)

---

## 14주차: 논문 초고 작성

### 주요목표 및 활동
학술 논문의 구조를 확정하고 초록을 작성한다. Introduction, Related Work, Methodology 섹션을 작성하여 논문 초고의 50%를 완성한다.

### 상세내용
"QuartzOpsBench: Operational, Reproducible, and Secure Evaluation of Multi-Agent Financial Decision Pipelines"를 주제로 논문 작성에 착수한다. 초록에서 연구의 핵심 기여(AgentOps 관점의 금융 LLM 평가, Trace Schema 표준화, 구조적 설계의 영향 실증)를 명확히 제시한다. Introduction에서 연구 동기와 가설을 서술하고, Related Work에서 FinBen, InvestorBench, AgentBench 등 기존 연구와의 차별점을 명시한다. Methodology에서 quartzopsbench 프레임워크 구조, Episode Dataset 스키마, Trace Schema 규격, 평가 지표 체계를 상세히 기술한다. 논문 작성 과정에서 지도교수님의 피드백을 반영하여 학술적 완결성을 높인다.

### 팀원별 목표 및 활동 (투입시간: 인당 25h)
- **강연욱**: 논문 전체 구조 설계, 초록 및 Introduction 작성, Related Work 작성, 논문 작성 총괄 (25h)
- **김장수**: Methodology 섹션 작성(Trace Schema, 평가 지표 체계), 기술적 세부사항 기술, 그림/다이어그램 제작 (25h)
- **오성현**: Methodology 섹션 작성(Episode Dataset, 데이터 파이프라인), 데이터셋 통계 정리, 표/차트 제작 (25h)

---

## 15주차: 논문 완성 및 오픈소스 정리

### 주요목표 및 활동
Experiments, Results, Conclusion 섹션을 작성하여 논문 초고를 완성한다. GitHub 저장소를 정리하고 README를 작성하여 오픈소스 공개를 준비한다.

### 상세내용
논문의 나머지 섹션을 완성한다. Experiments에서 비교 실험 설계(단일 LLM vs 규칙 기반 vs 멀티에이전트, LLM provider 교체 실험)를 기술하고, Results에서 실험 결과를 표와 그래프로 제시하며 분석 내용을 서술한다. Conclusion에서 연구의 학술적 기여, 한계점, 향후 연구 방향을 정리한다. 동시에 GitHub 저장소를 정리하여 오픈소스 공개를 준비한다. 코드 정리, 주석 추가, 설치 및 실행 가이드 작성, 라이선스 선정 등을 수행한다. README.md에 프로젝트 개요, 설치 방법, 사용 예시, 벤치마크 실행 방법을 명시한다.

### 팀원별 목표 및 활동 (투입시간: 인당 25h)
- **강연욱**: Results 및 Conclusion 작성, 논문 전체 리뷰 및 수정, GitHub 저장소 구조 정리, README.md 작성 (25h)
- **김장수**: Experiments 섹션 작성, 실험 결과 표/그래프 제작, 코드 주석 추가 및 문서화 (25h)
- **오성현**: 데이터셋 관련 섹션 작성, Episode Dataset 공개 준비, 데이터셋 사용 가이드 작성 (25h)

---

## 16주차: 최종 검토 및 제출

### 주요목표 및 활동
논문에 대한 피드백을 반영하여 최종 수정한다. 오픈소스 문서화를 완료하고 학회 투고를 준비하여 프로젝트를 마무리한다.

### 상세내용
지도교수님 및 동료 리뷰어의 피드백을 반영하여 논문을 최종 수정한다. 논문의 논리적 흐름, 실험 결과의 해석, 기여 주장의 명확성을 점검하고 보완한다. 참고문헌 형식, 그림/표 캡션, 영문법 등 형식적 요소를 최종 검토한다. quartzopsbench 실행 프레임워크, Episode Dataset, Trace Schema를 GitHub에 공개하고, 오픈소스 문서화를 완료한다. 재현 가능성 테스트를 수행하여 "한 번의 실행으로 결과가 재현되는" 벤치마크 도구임을 검증한다. 국내외 학술대회(KSC, EMNLP, ACL Findings 등) 투고 일정에 맞춰 논문 제출을 준비한다.

### 팀원별 목표 및 활동 (투입시간: 인당 20h)
- **강연욱**: 논문 최종 수정 총괄, 학회 투고 준비, GitHub 저장소 최종 공개, 오픈소스 라이선스 확정 (20h)
- **김장수**: 논문 기술적 내용 최종 검토, 코드 재현성 테스트, Trace Schema 문서 최종 검토 (20h)
- **오성현**: Episode Dataset 공개 및 문서화 완료, 데이터셋 재현성 검증, 프로젝트 최종 정리 (20h)

