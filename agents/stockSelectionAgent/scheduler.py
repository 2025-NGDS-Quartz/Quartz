import logging
import time
from datetime import datetime
from pathlib import Path
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
import signal
import sys

from news_crawler import MultiNewsCrawler
from news_pipeline import NewsPipeline

class AutomationScheduler:
    """ìë™í™” ìŠ¤ì¼€ì¤„ëŸ¬"""
    
    def __init__(self):
        self.setup_logging()
        self.scheduler = BackgroundScheduler()
        self.crawler = MultiNewsCrawler()
        self.pipeline = NewsPipeline()
        self.logger = logging.getLogger(__name__)
        
        # ì‹¤í–‰ í†µê³„
        self.stats = {
            'total_runs': 0,
            'successful_runs': 0,
            'failed_runs': 0,
            'last_run': None,
            'last_success': None,
            'last_error': None
        }
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        log_dir = Path("./data/logs")
        log_dir.mkdir(parents=True, exist_ok=True)
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬
        file_handler = logging.FileHandler(
            log_dir / "scheduler.log",
            encoding='utf-8'
        )
        file_handler.setLevel(logging.INFO)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # í¬ë§·
        formatter = logging.Formatter(
            '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        # ë£¨íŠ¸ ë¡œê±° ì„¤ì •
        root_logger = logging.getLogger()
        root_logger.setLevel(logging.INFO)
        root_logger.addHandler(file_handler)
        root_logger.addHandler(console_handler)
        
        self.logger = logging.getLogger(__name__)
    
    def crawl_and_process(self):
        """í¬ë¡¤ë§ ë° ì²˜ë¦¬ ì‘ì—…"""
        self.logger.info("="*80)
        self.logger.info("ğŸ¤– AUTOMATED TASK STARTED")
        self.logger.info("="*80)
        
        self.stats['total_runs'] += 1
        self.stats['last_run'] = datetime.now().isoformat()
        
        try:
            # 1. í¬ë¡¤ë§
            self.logger.info("ğŸ“° Step 1/2: Crawling news...")
            crawl_start = time.time()
            
            news_file = self.crawler.run(sources=['naver', 'hankyung', 'mk'], pages=3)
            
            crawl_time = time.time() - crawl_start
            self.logger.info(f"âœ… Crawling completed in {crawl_time:.2f}s")
            self.logger.info(f"ğŸ“ Saved to: {news_file}")
            
            # 2. íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬
            self.logger.info("ğŸ”„ Step 2/2: Processing pipeline...")
            pipeline_start = time.time()
            
            result_file = self.pipeline.run(news_file)
            
            pipeline_time = time.time() - pipeline_start
            self.logger.info(f"âœ… Pipeline completed in {pipeline_time:.2f}s")
            self.logger.info(f"ğŸ“ Results: {result_file}")
            
            # ì„±ê³µ
            self.stats['successful_runs'] += 1
            self.stats['last_success'] = datetime.now().isoformat()
            
            total_time = crawl_time + pipeline_time
            
            self.logger.info("="*80)
            self.logger.info(f"âœ… AUTOMATED TASK COMPLETED (Total: {total_time:.2f}s)")
            self.logger.info(f"ğŸ“Š Success Rate: {self.stats['successful_runs']}/{self.stats['total_runs']}")
            self.logger.info("="*80)
            
        except Exception as e:
            self.stats['failed_runs'] += 1
            self.stats['last_error'] = str(e)
            
            self.logger.error("="*80)
            self.logger.error(f"âŒ AUTOMATED TASK FAILED")
            self.logger.error(f"Error: {e}", exc_info=True)
            self.logger.error("="*80)
    
    def get_statistics(self):
        """í†µê³„ ì¶œë ¥"""
        self.logger.info("\n" + "="*80)
        self.logger.info("ğŸ“Š SCHEDULER STATISTICS")
        self.logger.info("="*80)
        self.logger.info(f"Total runs: {self.stats['total_runs']}")
        self.logger.info(f"Successful: {self.stats['successful_runs']}")
        self.logger.info(f"Failed: {self.stats['failed_runs']}")
        
        if self.stats['last_run']:
            self.logger.info(f"Last run: {self.stats['last_run']}")
        if self.stats['last_success']:
            self.logger.info(f"Last success: {self.stats['last_success']}")
        if self.stats['last_error']:
            self.logger.info(f"Last error: {self.stats['last_error']}")
        
        self.logger.info("="*80 + "\n")
    
    def start(self, run_immediately: bool = True):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        self.logger.info("ğŸš€ Starting automation scheduler...")
        
        # 12ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰ (ë§¤ì¼ 0ì‹œ, 12ì‹œ ì •ê°)
        self.scheduler.add_job(
            self.crawl_and_process,
            trigger=CronTrigger(hour='0,12', minute=0),  # ë§¤ì¼ 0ì‹œ, 12ì‹œ
            id='twice_daily_crawl',
            name='Twice Daily News Crawling & Processing',
            max_instances=1  # ë™ì‹œì— í•˜ë‚˜ë§Œ ì‹¤í–‰
        )
        
        # ë§¤ì¼ ìì •ì— í†µê³„ ì¶œë ¥
        self.scheduler.add_job(
            self.get_statistics,
            trigger=CronTrigger(hour=0, minute=0),
            id='daily_stats',
            name='Daily Statistics'
        )
        
        self.scheduler.start()
        
        self.logger.info("âœ… Scheduler started")
        self.logger.info("â° Schedule: Every 12 hours (00:00, 12:00)")
        self.logger.info("ğŸ“Š Stats: Daily at 00:00")
        
        # ì¦‰ì‹œ ì‹¤í–‰ ì˜µì…˜
        if run_immediately:
            self.logger.info("ğŸƒ Running immediately...")
            self.crawl_and_process()
        else:
            self.logger.info("â³ Waiting for next scheduled time...")
        
        # ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ì¶œë ¥
        jobs = self.scheduler.get_jobs()
        for job in jobs:
            self.logger.info(f"ğŸ“… Next run of '{job.name}': {job.next_run_time}")
    
    def stop(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€"""
        self.logger.info("ğŸ›‘ Stopping scheduler...")
        self.scheduler.shutdown()
        self.get_statistics()
        self.logger.info("âœ… Scheduler stopped")


def signal_handler(signum, frame):
    """ì¢…ë£Œ ì‹ í˜¸ ì²˜ë¦¬"""
    print("\nâš ï¸  Received interrupt signal. Shutting down gracefully...")
    sys.exit(0)


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    # ì‹ í˜¸ í•¸ë“¤ëŸ¬ ë“±ë¡ (Ctrl+C)
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
    scheduler = AutomationScheduler()
    
    print("\n" + "ğŸ¤– "*30)
    print("AUTOMATED STOCK SELECTION AGENT")
    print("ğŸ¤– "*30)
    print("\nğŸ“‹ Configuration:")
    print("  - Crawl & Process: Every 12 hours (00:00, 12:00)")
    print("  - Statistics: Daily at 00:00")
    print("  - Sources: Naver, Hankyung, MK")
    print("  - Pages per source: 3")
    print("\nğŸ’¡ Press Ctrl+C to stop\n")
    print("="*80 + "\n")
    
    try:
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ (ì¦‰ì‹œ ì‹¤í–‰)
        scheduler.start(run_immediately=True)
        
        # ê³„ì† ì‹¤í–‰
        while True:
            time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬
            
    except (KeyboardInterrupt, SystemExit):
        scheduler.stop()
        print("\nğŸ‘‹ Goodbye!\n")


if __name__ == "__main__":
    main()