import json
import logging
from pathlib import Path
from typing import List, Dict
from datetime import datetime
from collections import defaultdict
from stock_match.stock_dictionary import StockDictionary

class StockAggregator:
    """ì¢…ëª©ë³„ ë‰´ìŠ¤ ì§‘ê³„ ë° ë¶„ì„"""
    
    def __init__(self):
        self.dictionary = StockDictionary()
        self.logger = logging.getLogger(__name__)
    
    def aggregate_by_stock(self, news_items: List[Dict]) -> Dict[str, Dict]:
        """ì¢…ëª©ë³„ë¡œ ë‰´ìŠ¤ ì§‘ê³„"""
        self.logger.info("ğŸ“Š Aggregating news by stock...")
        
        # ì¢…ëª©ë³„ ë‰´ìŠ¤ ê·¸ë£¹í™”
        stock_news = defaultdict(list)
        
        for item in news_items:
            tickers = item.get('tickers', [])
            for ticker in tickers:
                stock_news[ticker].append(item)
        
        self.logger.info(f"âœ… Found {len(stock_news)} unique stocks")
        
        # ì¢…ëª©ë³„ í†µê³„ ê³„ì‚°
        aggregated = {}
        
        for ticker, news_list in stock_news.items():
            aggregated[ticker] = self._calculate_stock_stats(ticker, news_list)
        
        return aggregated
    
    def _calculate_stock_stats(self, ticker: str, news_list: List[Dict]) -> Dict:
        """ê°œë³„ ì¢…ëª© í†µê³„ ê³„ì‚°"""
        # ê¸°ë³¸ ì •ë³´
        name = self.dictionary.get_name(ticker)
        sector = self.dictionary.get_sector(ticker)
        
        # ê°ì„± ì ìˆ˜ ìˆ˜ì§‘
        sentiment_scores = []
        sentiments = {'positive': 0, 'negative': 0, 'neutral': 0}
        
        for news in news_list:
            score = news.get('sentiment_score', 0.5)
            sentiment_scores.append(score)
            
            sentiment = news.get('sentiment', 'neutral')
            sentiments[sentiment] += 1
        
        # í†µê³„
        total_news = len(news_list)
        avg_sentiment = sum(sentiment_scores) / total_news if total_news > 0 else 0.5
        
        positive_ratio = sentiments['positive'] / total_news if total_news > 0 else 0
        negative_ratio = sentiments['negative'] / total_news if total_news > 0 else 0
        neutral_ratio = sentiments['neutral'] / total_news if total_news > 0 else 0
        
        # ìš°ì„ ìˆœìœ„ ê²°ì •
        priority = self._determine_priority(avg_sentiment, total_news, positive_ratio)
        
        # ì¶”ì²œ ì´ìœ 
        reasoning = self._generate_reasoning(
            avg_sentiment, total_news, 
            sentiments['positive'], sentiments['negative']
        )
        
        # ìƒìœ„ í—¤ë“œë¼ì¸ (ìµœëŒ€ 5ê°œ)
        top_headlines = [
            news['headline'] 
            for news in sorted(news_list, key=lambda x: x.get('sentiment_score', 0), reverse=True)[:5]
        ]
        
        return {
            'ticker': ticker,
            'name': name,
            'sector': sector,
            'avg_sentiment': round(avg_sentiment, 3),
            'news_count': total_news,
            'positive_count': sentiments['positive'],
            'negative_count': sentiments['negative'],
            'neutral_count': sentiments['neutral'],
            'positive_ratio': round(positive_ratio, 3),
            'negative_ratio': round(negative_ratio, 3),
            'neutral_ratio': round(neutral_ratio, 3),
            'priority': priority,
            'reasoning': reasoning,
            'top_headlines': top_headlines
        }
    
    def _determine_priority(self, avg_sentiment: float, news_count: int, positive_ratio: float) -> str:
        """ìš°ì„ ìˆœìœ„ ê²°ì • ë¡œì§"""
        # HIGH: í‰ê·  ê°ì„± 0.7 ì´ìƒ + ë‰´ìŠ¤ 3ê°œ ì´ìƒ
        if avg_sentiment >= 0.7 and news_count >= 3:
            return "HIGH"
        
        # MID: í‰ê·  ê°ì„± 0.5 ì´ìƒ + ë‰´ìŠ¤ 2ê°œ ì´ìƒ
        elif avg_sentiment >= 0.5 and news_count >= 2:
            return "MID"
        
        # LOW: ê·¸ ì™¸
        else:
            return "LOW"
    
    def _generate_reasoning(self, avg_sentiment: float, news_count: int, 
                           positive_count: int, negative_count: int) -> str:
        """ì¶”ì²œ ì´ìœ  ìƒì„±"""
        sentiment_desc = "ê¸ì •ì " if avg_sentiment >= 0.6 else "ë¶€ì •ì " if avg_sentiment <= 0.4 else "ì¤‘ë¦½ì "
        
        reasoning = f"í‰ê·  ê°ì„± {avg_sentiment:.2f}({sentiment_desc}), "
        reasoning += f"ì´ {news_count}ê°œ ë‰´ìŠ¤, "
        reasoning += f"ê¸ì • {positive_count}ê°œ, ë¶€ì • {negative_count}ê°œ"
        
        return reasoning
    
    def get_top_stocks(self, aggregated: Dict[str, Dict], top_n: int = 20) -> List[Dict]:
        """ìƒìœ„ Nê°œ ì¢…ëª© ì„ ì •"""
        # ìš°ì„ ìˆœìœ„ ì ìˆ˜ ê³„ì‚°
        def calculate_score(stock_data: Dict) -> float:
            priority_weight = {'HIGH': 3.0, 'MID': 2.0, 'LOW': 1.0}
            
            score = stock_data['avg_sentiment'] * 0.7  # ê°ì„± ì ìˆ˜ 70%
            score += (stock_data['news_count'] / 10) * 0.2  # ë‰´ìŠ¤ ê°œìˆ˜ 20%
            score += priority_weight[stock_data['priority']] * 0.1  # ìš°ì„ ìˆœìœ„ 10%
            
            return score
        
        # ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
        stock_list = list(aggregated.values())
        for stock in stock_list:
            stock['final_score'] = calculate_score(stock)
        
        # ìƒìœ„ Nê°œ ì„ ì •
        top_stocks = sorted(stock_list, key=lambda x: x['final_score'], reverse=True)[:top_n]
        
        return top_stocks
    
    def save_candidates(self, aggregated: Dict[str, Dict], 
                       output_file: str = "data/stock_candidates.json") -> str:
        """ê±°ë˜ í›„ë³´ ì¢…ëª© ì €ì¥"""
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ìƒìœ„ ì¢…ëª© ì„ ì •
        top_stocks = self.get_top_stocks(aggregated, top_n=20)
        
        # í†µê³„
        total_stocks = len(aggregated)
        high_priority = sum(1 for s in aggregated.values() if s['priority'] == 'HIGH')
        mid_priority = sum(1 for s in aggregated.values() if s['priority'] == 'MID')
        low_priority = sum(1 for s in aggregated.values() if s['priority'] == 'LOW')
        
        data = {
            'timestamp': datetime.now().isoformat(),
            'total_stocks': total_stocks,
            'statistics': {
                'high_priority': high_priority,
                'mid_priority': mid_priority,
                'low_priority': low_priority
            },
            'top_candidates': top_stocks,
            'all_stocks': aggregated
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"ğŸ’¾ Saved {len(top_stocks)} top candidates to {output_path}")
        return str(output_path)
    
    def print_summary(self, aggregated: Dict[str, Dict], top_n: int = 10):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        top_stocks = self.get_top_stocks(aggregated, top_n=top_n)
        
        print("\n" + "="*80)
        print(f"ğŸ“Š TOP {top_n} STOCK CANDIDATES")
        print("="*80)
        
        for i, stock in enumerate(top_stocks, 1):
            priority_emoji = {
                'HIGH': 'ğŸ”¥',
                'MID': 'âš¡',
                'LOW': 'ğŸ’¡'
            }
            emoji = priority_emoji.get(stock['priority'], 'â“')
            
            print(f"\n[{i}] {emoji} {stock['priority']} - {stock['ticker']}: {stock['name']}")
            print(f"    ì„¹í„°: {stock['sector']}")
            print(f"    í‰ê·  ê°ì„±: {stock['avg_sentiment']:.3f} (ë‰´ìŠ¤ {stock['news_count']}ê°œ)")
            print(f"    ê¸ì •/ë¶€ì •: {stock['positive_count']}ê°œ / {stock['negative_count']}ê°œ")
            print(f"    ìµœì¢… ì ìˆ˜: {stock['final_score']:.3f}")
            print(f"    ì´ìœ : {stock['reasoning']}")
            print(f"    ëŒ€í‘œ í—¤ë“œë¼ì¸: {stock['top_headlines'][0][:60]}...")


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    aggregator = StockAggregator()
    
    # ì²˜ë¦¬ëœ ë‰´ìŠ¤ íŒŒì¼ ë¡œë“œ
    processed_dir = Path("./data/processed")
    processed_files = sorted(processed_dir.glob("*.json"), reverse=True)
    
    if not processed_files:
        print("âŒ ì²˜ë¦¬ëœ ë‰´ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € news_pipeline.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    else:
        latest_file = processed_files[0]
        print(f"ğŸ“ Loading: {latest_file.name}\n")
        
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        news_items = data['news']
        
        # ì§‘ê³„
        aggregated = aggregator.aggregate_by_stock(news_items)
        
        # ìš”ì•½ ì¶œë ¥
        aggregator.print_summary(aggregated, top_n=10)
        
        # ì €ì¥
        output_path = aggregator.save_candidates(aggregated)
        print(f"\nâœ… Saved to: {output_path}")