import os
import json
import logging
from pathlib import Path
from typing import List, Dict, Optional
from datetime import datetime
from collections import defaultdict

import boto3
from botocore.exceptions import ClientError

from stock_match.stock_dictionary import StockDictionary

# AWS S3 ì„¤ì •
AWS_REGION = os.getenv("AWS_REGION", "ap-northeast-2")
S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME", "quartz-bucket")
S3_CANDIDATES_KEY = "select-ticker/stock_candidates.json"


class StockAggregator:
    """ì¢…ëª©ë³„ ë‰´ìŠ¤ ì§‘ê³„ ë° ë¶„ì„"""
    
    def __init__(self):
        self.dictionary = StockDictionary()
        self.logger = logging.getLogger(__name__)
    
    def aggregate_by_stock(self, news_items: List[Dict]) -> Dict[str, Dict]:
        """ì¢…ëª©ë³„ë¡œ ë‰´ìŠ¤ ì§‘ê³„"""
        self.logger.info("ğŸ“Š Aggregating news by stock...")
        
        # ì¢…ëª©ë³„ ë‰´ìŠ¤ ê·¸ë£¹í™”
        stock_news = defaultdict(list)
        
        for item in news_items:
            tickers = item.get('tickers', [])
            for ticker in tickers:
                stock_news[ticker].append(item)
        
        self.logger.info(f"âœ… Found {len(stock_news)} unique stocks")
        
        # ì¢…ëª©ë³„ í†µê³„ ê³„ì‚°
        aggregated = {}
        
        for ticker, news_list in stock_news.items():
            aggregated[ticker] = self._calculate_stock_stats(ticker, news_list)
        
        return aggregated
    
    def _calculate_stock_stats(self, ticker: str, news_list: List[Dict]) -> Dict:
        """ê°œë³„ ì¢…ëª© í†µê³„ ê³„ì‚°"""
        # ê¸°ë³¸ ì •ë³´
        name = self.dictionary.get_name(ticker)
        sector = self.dictionary.get_sector(ticker)
        
        # ê°ì„± ì ìˆ˜ ìˆ˜ì§‘
        sentiment_scores = []
        sentiments = {'positive': 0, 'negative': 0, 'neutral': 0}
        
        for news in news_list:
            score = news.get('sentiment_score', 0.5)
            sentiment_scores.append(score)
            
            sentiment = news.get('sentiment', 'neutral')
            sentiments[sentiment] += 1
        
        # í†µê³„
        total_news = len(news_list)
        avg_sentiment = sum(sentiment_scores) / total_news if total_news > 0 else 0.5
        
        positive_ratio = sentiments['positive'] / total_news if total_news > 0 else 0
        negative_ratio = sentiments['negative'] / total_news if total_news > 0 else 0
        neutral_ratio = sentiments['neutral'] / total_news if total_news > 0 else 0
        
        # ìš°ì„ ìˆœìœ„ ê²°ì •
        priority = self._determine_priority(avg_sentiment, total_news, positive_ratio)
        
        # ì¶”ì²œ ì´ìœ 
        reasoning = self._generate_reasoning(
            avg_sentiment, total_news, 
            sentiments['positive'], sentiments['negative']
        )
        
        # ìƒìœ„ í—¤ë“œë¼ì¸ (ìµœëŒ€ 5ê°œ)
        top_headlines = [
            news['headline'] 
            for news in sorted(news_list, key=lambda x: x.get('sentiment_score', 0), reverse=True)[:5]
        ]
        
        return {
            'ticker': ticker,
            'name': name,
            'sector': sector,
            'avg_sentiment': round(avg_sentiment, 3),
            'news_count': total_news,
            'positive_count': sentiments['positive'],
            'negative_count': sentiments['negative'],
            'neutral_count': sentiments['neutral'],
            'positive_ratio': round(positive_ratio, 3),
            'negative_ratio': round(negative_ratio, 3),
            'neutral_ratio': round(neutral_ratio, 3),
            'priority': priority,
            'reasoning': reasoning,
            'top_headlines': top_headlines
        }
    
    def _determine_priority(self, avg_sentiment: float, news_count: int, positive_ratio: float) -> str:
        """ìš°ì„ ìˆœìœ„ ê²°ì • ë¡œì§"""
        # HIGH: í‰ê·  ê°ì„± 0.7 ì´ìƒ + ë‰´ìŠ¤ 3ê°œ ì´ìƒ
        if avg_sentiment >= 0.7 and news_count >= 3:
            return "HIGH"
        
        # MID: í‰ê·  ê°ì„± 0.5 ì´ìƒ + ë‰´ìŠ¤ 2ê°œ ì´ìƒ
        elif avg_sentiment >= 0.5 and news_count >= 2:
            return "MID"
        
        # LOW: ê·¸ ì™¸
        else:
            return "LOW"
    
    def _generate_reasoning(self, avg_sentiment: float, news_count: int, 
                           positive_count: int, negative_count: int) -> str:
        """ì¶”ì²œ ì´ìœ  ìƒì„±"""
        sentiment_desc = "ê¸ì •ì " if avg_sentiment >= 0.6 else "ë¶€ì •ì " if avg_sentiment <= 0.4 else "ì¤‘ë¦½ì "
        
        reasoning = f"í‰ê·  ê°ì„± {avg_sentiment:.2f}({sentiment_desc}), "
        reasoning += f"ì´ {news_count}ê°œ ë‰´ìŠ¤, "
        reasoning += f"ê¸ì • {positive_count}ê°œ, ë¶€ì • {negative_count}ê°œ"
        
        return reasoning
    
    def get_top_stocks(self, aggregated: Dict[str, Dict], top_n: int = 5) -> List[Dict]:
        """
        ìƒìœ„ Nê°œ ì¢…ëª© ì„ ì • (ì¤‘ìš”ë„ ê¸°ë°˜ í•„í„°ë§)
        
        ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚°:
        - ì‹œì´ ë“±ê¸‰ ê°€ì¤‘ì¹˜: 25% (LARGE=1.0, MID=0.6, SMALL=0.3)
        - ê°ì„± ì ìˆ˜: 40%
        - ë‰´ìŠ¤ ê°œìˆ˜ (ì–¸ë¡  ì–¸ê¸‰): 25%
        - ìš°ì„ ìˆœìœ„: 10%
        """
        def calculate_importance_score(stock_data: Dict) -> float:
            ticker = stock_data['ticker']
            
            # ì‹œì´ ê°€ì¤‘ì¹˜ (25%)
            market_cap_weight = self.dictionary.get_market_cap_weight(ticker)
            
            # ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜
            priority_weight = {'HIGH': 1.0, 'MID': 0.6, 'LOW': 0.3}
            
            # ë‰´ìŠ¤ ê°œìˆ˜ ì •ê·œí™” (ìµœëŒ€ 10ê°œ ê¸°ì¤€)
            news_score = min(stock_data['news_count'] / 10, 1.0)
            
            # ìµœì¢… ì ìˆ˜ ê³„ì‚°
            score = market_cap_weight * 0.25  # ì‹œì´ 25%
            score += stock_data['avg_sentiment'] * 0.40  # ê°ì„± 40%
            score += news_score * 0.25  # ë‰´ìŠ¤ ê°œìˆ˜ 25%
            score += priority_weight.get(stock_data['priority'], 0.3) * 0.10  # ìš°ì„ ìˆœìœ„ 10%
            
            return score
        
        # ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
        stock_list = list(aggregated.values())
        for stock in stock_list:
            stock['final_score'] = calculate_importance_score(stock)
            stock['market_cap_tier'] = self.dictionary.get_market_cap_tier(stock['ticker'])
        
        # ìƒìœ„ Nê°œ ì„ ì • (ê¸°ë³¸ 5ê°œ)
        top_stocks = sorted(stock_list, key=lambda x: x['final_score'], reverse=True)[:top_n]
        
        return top_stocks
    
    def save_candidates(self, aggregated: Dict[str, Dict], 
                       output_file: str = "data/stock_candidates.json") -> str:
        """ê±°ë˜ í›„ë³´ ì¢…ëª© ì €ì¥ (ë¡œì»¬ + S3)"""
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ìƒìœ„ ì¢…ëª© ì„ ì • (ì¤‘ìš”ë„ ê¸°ë°˜, ìµœëŒ€ 5ê°œ)
        top_stocks = self.get_top_stocks(aggregated, top_n=5)
        
        # í†µê³„
        total_stocks = len(aggregated)
        high_priority = sum(1 for s in aggregated.values() if s['priority'] == 'HIGH')
        mid_priority = sum(1 for s in aggregated.values() if s['priority'] == 'MID')
        low_priority = sum(1 for s in aggregated.values() if s['priority'] == 'LOW')
        
        data = {
            'timestamp': datetime.now().isoformat(),
            'total_stocks': total_stocks,
            'statistics': {
                'high_priority': high_priority,
                'mid_priority': mid_priority,
                'low_priority': low_priority
            },
            'top_candidates': top_stocks,
            'all_stocks': aggregated
        }
        
        # ë¡œì»¬ ì €ì¥
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"ğŸ’¾ Saved {len(top_stocks)} top candidates to {output_path}")
        
        # S3 ì—…ë¡œë“œ
        self._upload_to_s3(data)
        
        return str(output_path)
    
    def _upload_to_s3(self, data: Dict) -> bool:
        """S3ì— í›„ë³´ ì¢…ëª© ë°ì´í„° ì—…ë¡œë“œ"""
        try:
            s3_client = boto3.client('s3', region_name=AWS_REGION)
            
            json_content = json.dumps(data, ensure_ascii=False, indent=2)
            
            s3_client.put_object(
                Bucket=S3_BUCKET_NAME,
                Key=S3_CANDIDATES_KEY,
                Body=json_content.encode('utf-8'),
                ContentType="application/json"
            )
            
            self.logger.info(f"â˜ï¸ Uploaded candidates to S3: s3://{S3_BUCKET_NAME}/{S3_CANDIDATES_KEY}")
            return True
            
        except ClientError as e:
            self.logger.error(f"Failed to upload to S3: {e}")
            return False
        except Exception as e:
            self.logger.error(f"S3 upload error: {e}")
            return False
    
    def print_summary(self, aggregated: Dict[str, Dict], top_n: int = 5):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥ (ì¤‘ìš”ë„ ê¸°ë°˜ ìƒìœ„ ì¢…ëª©)"""
        top_stocks = self.get_top_stocks(aggregated, top_n=top_n)
        
        print("\n" + "="*80)
        print(f"ğŸ“Š TOP {top_n} STOCK CANDIDATES (Importance-Based)")
        print("="*80)
        
        market_cap_emoji = {'LARGE': 'ğŸ¢', 'MID': 'ğŸ ', 'SMALL': 'ğŸšï¸'}
        priority_emoji = {'HIGH': 'ğŸ”¥', 'MID': 'âš¡', 'LOW': 'ğŸ’¡'}
        
        for i, stock in enumerate(top_stocks, 1):
            p_emoji = priority_emoji.get(stock['priority'], 'â“')
            m_emoji = market_cap_emoji.get(stock.get('market_cap_tier', 'SMALL'), 'â“')
            
            print(f"\n[{i}] {p_emoji} {stock['priority']} | {m_emoji} {stock.get('market_cap_tier', 'N/A')} - {stock['ticker']}: {stock['name']}")
            print(f"    ì„¹í„°: {stock['sector']}")
            print(f"    í‰ê·  ê°ì„±: {stock['avg_sentiment']:.3f} (ë‰´ìŠ¤ {stock['news_count']}ê°œ)")
            print(f"    ê¸ì •/ë¶€ì •: {stock['positive_count']}ê°œ / {stock['negative_count']}ê°œ")
            print(f"    ì¤‘ìš”ë„ ì ìˆ˜: {stock['final_score']:.3f}")
            print(f"    ì´ìœ : {stock['reasoning']}")
            if stock['top_headlines']:
                print(f"    ëŒ€í‘œ í—¤ë“œë¼ì¸: {stock['top_headlines'][0][:60]}...")


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    aggregator = StockAggregator()
    
    # ì²˜ë¦¬ëœ ë‰´ìŠ¤ íŒŒì¼ ë¡œë“œ
    processed_dir = Path("./data/processed")
    processed_files = sorted(processed_dir.glob("*.json"), reverse=True)
    
    if not processed_files:
        print("âŒ ì²˜ë¦¬ëœ ë‰´ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € news_pipeline.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    else:
        latest_file = processed_files[0]
        print(f"ğŸ“ Loading: {latest_file.name}\n")
        
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        news_items = data['news']
        
        # ì§‘ê³„
        aggregated = aggregator.aggregate_by_stock(news_items)
        
        # ìš”ì•½ ì¶œë ¥
        aggregator.print_summary(aggregated, top_n=10)
        
        # ì €ì¥
        output_path = aggregator.save_candidates(aggregated)
        print(f"\nâœ… Saved to: {output_path}")